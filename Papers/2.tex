\\
Earlier, Hazarika et. al. \cite{Hazarika2019ConversationalTL} discussed the possibility of using transformers to capture context better and the need to find sentimental coherence between utterances, an area explored by the current study. Shen et. al. highlighted two key weaknesses of existing research in conversation modelling. They noted that many recent studies focused on encoding utterances as representations, which while systemically preserving the hierarchical and sequential organisation of dialogues, failed to facilitate pre-trained language models like BERT \cite{Devlin2019BERTPO} and XLNet \cite{Yang2019XLNetGA} from astutely capturing the direct dependencies between words in them. They also noted that these language models were handicapped by lengthy input sequences that frequently needed to be shortened, rendering them less advantageous due to the loss of information from far-off past utterances \cite{Ghosal2019DialogueGCNAG,Majumder2018DialogueRNNAA}. They reasoned that these models were not equipped to address more nuanced tasks like ERC, which encompass extensive chains of inter and intra speaker relationships \cite{Shen2020DialogXLAX}.

The primary objective of their work was to extend the capability of a pre-trained language model for the purpose of emotion recognition in dialogues. In order to combat the shortcomings presented by the aforementioned factors, they proposed a renewed model, DialogXL, a non-hierarchical network and adaptation of XLNet \cite{Yang2019XLNetGA}, for handling ERC in multi-turn and multi-party conversations. The development included two main ideas -- a) Replacing Transformer-XL's \cite{Dai2019TransformerXLAL} (from which XLNet was built) segment recurrence device with an \textit{utterance recurrence} mechanism to better capture historical context of up to a 1000 words. This enabled the model to better understand long-term dependencies, which are essential for tasks like ERC, that frequently deal with complete sentences and paragraphs. Additionally, this improvement also established a memory-efficient strategy for holding the hidden states of longer historical contexts into \textit{memory-banks} for future re-usability, by allowing for variable length sequences and releasing wasted padding memory blocks that were connected to fixed length sequences or \textit{segments}. b) Fleshing out the basic self-attention mechanism of the original transformer architecture with a \textit{dialogue-aware self-attention} component by infusing speaker roles and other relevant reception fields into it.

The embedding layer received an utterance prefixed with the \textit{[CLS]} token as input. The second tier of the DialogXL model was a transformer layer that included the previously stated \textit{utterance recurrence} and \textit{dialog aware self-attention} blocks. The memory unit in the utterance recurrence chamber concatenated and stacked the earlier utterances with the present one. To keep extraneous clutter away from the memory store, it contained an inherent mechanism that preserved just the hidden states of the utterance symbols along with the \textit{[CLS]} token and discarded the padding memory. The output from this block a new-updated memory. The attention segment contained four sub-units: a) Global self-attention, which took into account the context of all previous distant utterances; b) Local self-attention, with a flexible window size for receptive fields, where attention weights outside of the window were masked; c) Speaker self-attention; and d) Listener self-attention to model relationships between and within speakers, respectively. This unit did not require any additional embeddings or parameters. The outputs of the four sub-units were combined and then passed through a normalisation layer followed by a feed-forward network to generate the final output.

Shen et. al. evaluated their model on four datasets with emotions labels as follows -- IEMOCAP \cite{Busso2008IEMOCAPIE} :  \textit{neutral, happiness, sadness, anger, frustrated}, and \textit{excited}, DailyDialog \cite{Li2017DailyDialogAM} : \textit{neutral, happiness, surprise, sadness, anger, disgust}, and \textit{fear}, EmoryNLP \cite{Zahiri2017EmotionDO} : \textit{neutral, sad, mad, scared, powerful, peaceful}, and \textit{joyful} and MELD \cite{Poria2018MELDAM} : \textit{neutral, happiness, surprise, sadness, anger, disgust}, and \textit{fear}. As for the metrics, they chose the micro F1 score for the DialyDialog dataset, for reasons observed in the previous section on \cite{Hazarika2019ConversationalTL}. They made use of the weighted average F1 score for the remaining datasets. They compared their model's performance to the baseline approaches -- CMN \cite{Hazarika2018ConversationalMN}, DialogueRNN \cite{Majumder2018DialogueRNNAA}, TL-ERC \cite{Hazarika2019ConversationalTL}, DialogueGCN \cite{Ghosal2019DialogueGCNAG}, KET \cite{Zhong2019KnowledgeEnrichedTF} and HiGRU \cite{Jiao2019HiGRUHG}, BERT \cite{Devlin2019BERTPO} and XLNet \cite{Yang2019XLNetGA}.

Although DialogXL outperformed the leading-edge baseline models, it only slightly beat XLNet and BERT on short conversational datasets like DailyDialog, EmoryNLP, and MELD ($\approx$ 5-9 statements per conversation). Both XLNet and BERT were trained using the hyperparameters of DialogXL, with XLNet using segment recurrence and BERT using a combination of current and historical utterance representations. However, DialogXL outperformed all other models, including BERT and XLNet, on the long-utterance IEMOCAP dataset ($\approx$ 70 statements per conversation) with a weighted F1 score of 65.94. This showed that BERT and XLNet struggled to handle elongated contexts, while models like DialogueRNN and DialogueGCN, which encoded both speaker information and chronological contexts, were more effective in handling them. The authors evaluated three models to measure the waste of memory in terms of segment recurrence on the IEMOCAP dataset, which has long conversations per dialog. These models were: the original XLNet with segment recurrence, XLNet with utterance recurrence, and DialogXL. The latter two used utterance recurrence, leading to no padding memory waste. The experiment used a memory length capped at 1000 and an interval width of 100. The findings showed that the segment recurrence consistently caused a memory waste rate of 60\% or more. However, as the size increased, the rate gradually leveled off when the memory length surpassed 700, suggesting that increasing the memory length didn't necessarily have a significant benefit. Further investigations were conducted by the authors to assess the impact of each sub-unit of the \textit{dialog aware self-attention} module in DialogXL using the IEMOCAP and MELD datasets. The results reflected that the removal of the local self-attention had the largest effect on performance decline. This decrease was more pronounced on the IEMOCAP dataset, which consists of longer conversations. This demonstrated the significance of historical context neighbouring the current utterance. Another finding was that removing either listener or speaker self-attention or both had the second-highest impact on the model's performance. Both datasets showed similar results, highlighting the importance of inter and intra speaker dependencies. Finally, the authors found that the removal of global self-attention had the least effect on performance. They speculated that this could be due to either the global self-attention being less worthy or because the listener and speaker attentions caught some of the essential information from past utterances. Shen et. al. also experimented by replacing the listener and speaker self-attention mechanisms with a speaker role embedding vector \cite{Bao2019PLATOPD,Ham2020EndtoEndNP}. The F1 results from testing their DialogXL model on the DailyDialog and IEMOCAP datasets showed that this approach was not as effective as utilising the attention mechanisms directly. As a result, the authors suggest it as a potential addition to future models.

The researchers discovered that DialogXL's feature of grabbing details at the word-level from the historical contexts could sometimes backfire. The attention mechanism, centered around semantic relationships, had the potential to result in both accurate and inaccurate predictions. The negative scenario often occurred when a lot of importance was attached to past utterances. To illustrate their point, the researchers used two examples. In the first, the sentence \textit{``He's a fighter''} with the emotion label \textit{sad} was accurately predicted due to the preceding utterance \textit{``He's been sick for a while''} having a significant attention weight. However, the emotion label for the sentence \textit{``He was literally, literally the most talented guy''} was mistakenly predicted as \textit{happy} instead of \textit{sad}. This happened because the model placed too much emphasis on the previous utterance \textit{``And he's so talented''}, which on this occasion was used to express the speaker's regret for someone who had missed out on an opportunity. To achieve more reliable results in recognising emotions in dialogues, a more complete strategy was required instead of simply relying on attention mechanisms. Furthermore, the researchers noticed that a large portion (45\%) of the cases involving change in emotions between consecutive statements made by the same speaker resulted in errors, requiring additional thought.


