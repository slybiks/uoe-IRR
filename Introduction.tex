The study of emotions is important as they shape our everyday experiences and activities. Research into emotions has numerous benefits, such as improving mental health diagnosis, enhancing customer satisfaction, revolutionising education and e-learning, better understanding user behavior on social media, making informed decisions in finance and investments, and improving urban design and architecture by analyzing human behavior. From the viewpoint of computer science, the investigation of emotions is carried out across various forms of media, including facial expressions, oral communication, and written text \cite{Li2018DeepFE,Drakopoulos2019EmotionRF,Marchal2019SurveyOA, 10.1145/3136755.3136801}. Traditionally, crafted characteristics, including identifying emotional keywords, utilising resources related to emotion vocabulary, and hashtags, were used to study emotions \cite{Strapparava2004WordNetAA, Wang2012HarnessingT}. However, with the advent of deep learning, researchers now have the ability to automatically learn features. 

In particular, the field of Natural Language Processing has seen a surge of attention directed towards emotion recognition (ERC) and emotion inference in conversations. This is partly due to the availability of a large volume of datasets, an increase in interest in dialogue-based technologies and casual argumentation, and the desire to create conversational agents that are better able to understand and respond to the emotions of those they interact with in a human-like manner \cite{Liu2021LifelongAC,Bowman2015ALA, Tu2021ExplorationME}. Challenges in these tasks go beyond the normal difficulties in understanding dialogue, such as identifying intent and considering context. It involves modelling the emotional dynamics between people and accounting for self and inter-speaker influences. Additionally, there are issues with the limited amount of annotated data, especially for multi-modal emotion recognition, and variability in annotations because emotions can be subjective to interpret \cite{Chen2017ASO,hazarika-etal-2018-icon,Hazarika2019ConversationalTL,Poria2020BeneathTT}.

In that aspect, there has been a lot of interesting research in these areas in recent years. Many scholars have used RNNs to analyse the context and sequence of utterances in conversations in order to recognise emotions. For instance, some researchers proposed using c-LSTM networks to record contexts \cite{poria-etal-2017-context}, while others such as \cite{Hazarika2018ConversationalMN} presented a memory network specifically designed for conversation which relied on GRUs. They established separate models for both the addresser and addressee, then utilised the desired utterance as a search item to probe the models to form a representation of the utterance. Hazarika et. al. utilised two GRUs to acquire the representation of the speaker's and the listener's utterance, then combined the outputs of these GRUs with another GRU to conduct inter-speaker modeling explicitly in \cite{hazarika-etal-2018-icon}. However both LSTMs and GRUs had certain pitfalls in this regard \cite{Bradbury2016QuasiRecurrentNN}. Several sophisticated techniques such as the DialogueRNN propose by Majumder et. al. tackled these issues by using GRUs to keep tabs on the party states, contextual information from preceding utterances and the emotions they entailed \cite{Majumder2018DialogueRNNAA}. Similarly, Ghosal et. al. put forward a new technique, using graph-neural networks that considered the relationships between and within speakers to capture context \cite{Ghosal2019DialogueGCNAG}. As for emotion inference, Hasegawa et. al. \cite{hasegawa-etal-2013-predicting} attempted to recognise and predict the emotional response of the listener in an online conversation. 

Despite their potential, there is still room for improvement in benchmark methods. The emergence of new areas such as transfer learning for sentiment analysis \cite{DavalFrerot2018EpitaAS}, incorporating external knowledge to make dialogue systems more intelligent \cite{Ma2020ASO}, and the use of pre-trained language models for dialogue-based tasks \cite{Bao2019PLATOPD} offer opportunities for further innovations and serves as the main theme of this review.

Specifically, some inquiries aim to evaluate if the recent techniques perform better in the following areas --
\begin{enumerate*}
    \item Resolving contextual ambiguities
    \item Operating with limited data availability
    \item Grasping the diversity and extents of emotions
    \item Identifying emotion shifts
    \item Comprehending the context, history, and intents of the speaker.
\end{enumerate*}

The rest of this paper is organised as follows. Section 2 addresses the research topics by examining four separate studies in subsections 2.1, 2.2, 2.3, and 2.4 for transfer learning, enhancing pre-trained language models, and common sense integration for emotion inference and recognition, respectively. Section 3 includes a short summary and conclusion.






